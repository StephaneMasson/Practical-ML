<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title></title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<p>#Summary</p>

<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>. The goal of this project is to predict the manner in which they did the execise.</p>

<p>The dataset used in this project can be found here, and the experiment details are described in the original paper.</p>

<p>#Data</p>

<p>First of all, by executing the following step, we want to ensure that the data are available and loaded in R environment. </p>

<pre><code class="r, echo = FALSE">library(caret);library(kernlab)
</code></pre>

<pre><code class="r, echo = TRUE">trainset_url &lt;- &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;
testset_url &lt;-&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;

if(!file.exists(&quot;./mlearn_project&quot;)) {dir.create(&quot;./mlearn_project&quot;)}

download.file(trainset_url, &quot;mlearn_project/pml-training.csv&quot;, method = &quot;curl&quot;)
download.file(testset_url, &quot;mlearn_project/pml-testing.csv&quot;, method = &quot;curl&quot;)

train &lt;- read.csv(&quot;C:/Users/DATANALYSIS/Documents/RProgramming/mlearn_project/pml-training.csv&quot;,na.strings=c(&quot;&quot;,&quot;NA&quot;,&quot;#DIV/0!&quot;))
test &lt;- read.csv(&quot;C:/Users/DATANALYSIS/Documents/RProgramming/mlearn_project/pml-testing.csv&quot;,na.strings=c(&quot;&quot;,&quot;NA&quot;,&quot;#DIV/0!&quot;))
</code></pre>

<p>#Data exploration</p>

<p>In order to gain some knowledge about the data that we are wanting to analyse, we&#39;ll perform some basic exploration steps?</p>

<pre><code class="r, echo = TRUE">dim(train)
dim(test)
</code></pre>

<p>The two dataset are composed of:
-The training set consists of 19622 observations of 160 variables
-The testing set consists of 20 observations of 160 variables</p>

<p>We also notice that many columns are mostly filled with NA (NA is composed from the empty, NA and div/0 values in the raw dataset). Moreover the 7 first columns do not seem to have any value in the analysis. In order to perform the next steps, we&#39;ll get rid of those columns so that the analysis will be done on a clean data set.</p>

<pre><code class="r, echo = TRUE">NA_Count = sapply(1:dim(train)[2],function(x)sum(is.na(train[,x])))

#The columns where more than 50% of the values are NA are suppressed from the dataset
NA_list = which(NA_Count/19622&gt;0.5)

#The first seven columns are meaningless in the scope of our study
colnames(train[,c(1:7)])

train = train[,-NA_list]
train = train[,-c(1:7)]
train$classe = factor(train$classe)
</code></pre>

<p>We also do not want to keep in our dataset the predictors that have zero variance. </p>

<pre><code class="r, echo = TRUE">ColumnsZVar &lt;- nearZeroVar(train, saveMetrics = TRUE)
train &lt;- train[, ColumnsZVar$nzv==FALSE]
train$classe = factor(train$classe)
</code></pre>

<p>By performing the previous steps, the dataset on which the analysis will be performed is now ready. </p>

<p>#Partitioning the training data set to allow cross-validation</p>

<p>In order to evaluation the models that we are going to test in order to predict the manner in which the exercise was done, the provided trainset is split into 2 new subsets (60% of the train set will be used to train the different models and 40% will be used to evaluate their respective performance)</p>

<pre><code class="r, echo = TRUE">set.seed(1234)
subTrain &lt;- createDataPartition(y=train$classe, p=.6, list=FALSE)

training &lt;- train[subTrain, ]
testing &lt;- train[-subTrain, ]
</code></pre>

<p>#Model Training</p>

<p>We are facing a classification problem. We want to predict in which of the 5 categories (A, B, C, D, E) fall the data in the test set. As a consequence, we&#39;ll test three models from the R caret package that can predict the outcomes for a classification problem (decision tree and random forest). </p>

<p>In order to perform cross-validation, first we set up the trainControl parameters. </p>

<pre><code class="r, echo = TRUE">cv3 = trainControl(method=&quot;cv&quot;,number=3,allowParallel=TRUE,verboseIter=TRUE)
</code></pre>

<p>The first model, we&#39;ll try is a decision tree. Based on its caracteristics, we do not expect this model to have the best performances. </p>

<pre><code class="r, echo = TRUE">modrpart = train(classe~., data=training, method=&quot;rpart&quot;,trControl=cv3)
confusionMatrix(testing$classe, predict(modrpart,testing))
</code></pre>

<p>As expected, the performance of this model is average. </p>

<ul>
<li>Accuracy : 0.4904<br/></li>
<li>95% CI : (0.4793, 0.5016)</li>
<li>Kappa: 0.339</li>
</ul>

<p>In order to have a better prediction model, we&#39;ll train a Random Forest Classifier, which is one of the most accurate model available. However, it will be much slower to train it.  </p>

<pre><code class="r, echo = TRUE">modrf = train(classe~., data=training, method=&quot;rf&quot;,trControl=cv3, prox = TRUE)
confusionMatrix(testing$classe, predict(modrf,testing))
</code></pre>

<p>The performance of the random forest is way better than the decision tree:</p>

<ul>
<li>Accuracy : 0.9908<br/></li>
<li>95% CI : (0.9885, 0.9928)</li>
<li>Kappa : 0.9884<br/></li>
</ul>

<p>As a consequence, we&#39;ll use this model to predict the manner in which the exercise were done</p>

<p>#Prediction</p>

<p>We&#39;ll use the script provided by Coursera in order to generate the answer to the project. </p>

<pre><code class="r, echo = TRUE">answers=predict(modrf,test)
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0(&quot;problem_id_&quot;,i,&quot;.txt&quot;)
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
answers

pml_write_files(answers)
</code></pre>

<p>In conclusion, the 20 recording for which we were trying to predict the class are respectively:
B A B A A E D B A A B C B A E E A B B B</p>

</body>

</html>
